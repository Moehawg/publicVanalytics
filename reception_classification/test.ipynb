{"cells":[{"cell_type":"markdown","metadata":{"id":"bBgzHxADt6KS"},"source":["# Volleyball Reception Classification Report\n","\n","This notebook documents the complete development process of a binary classifier to distinguish between **\"upper\"** and **\"lower\"** volleyball receptions using skeleton keypoints extracted via a YOLO pose estimation model. The workflow covers data curation, cleaning, preprocessing, model training, evaluation, data augmentation, and final conclusions.\n"],"id":"bBgzHxADt6KS"},{"cell_type":"markdown","metadata":{"id":"4pEktKRDt6KV"},"source":["## 1. Introduction\n","\n","In recent years, **sports analytics** has grown into a powerful tool for performance optimization, tactical decision-making, and even injury prevention. Within this domain, **computer vision and machine learning** are playing increasingly important roles — offering insights that were previously unachievable at scale or in real time.\n","\n","This project is a **case study** in building a lightweight yet effective model for classifying **volleyball reception types** (\"upper\" vs. \"lower\") using only **skeleton keypoint data**, rather than full images or video. The use of **YOLO11x pose estimation** enables us to extract 2D joint coordinates for each player from video frames — offering a **computationally efficient** alternative to using full-resolution images.\n","\n","The classification task revolves around analyzing the **relative body posture** of the player performing the reception:\n","- In an **\"upper\" reception**, arms are typically raised above or level with the chest.\n","- In a **\"lower\" reception**, arms are extended downward or outward near the legs.\n","\n","By analyzing only this **structured pose data**, I demonstrate that it is possible to build a binary classifier using a simple **Multilayer Perceptron (MLP)** architecture.\n","\n","**Project Objectives:**\n","- Curate and clean a dataset of YOLO-based skeleton keypoints for volleyball receptions.\n","- Build and evaluate a classifier to distinguish between \"upper\" and \"lower\" receptions.\n","- Augment the dataset in a geometrically valid way to improve model generalization.\n","- Document the end-to-end pipeline to demonstrate  a reproducible ML workflow.\n","\n","**Upper Reception:**\n","\n","![Upper Reception](resource/upper_22.png)\n","\n","**Lower Reception:**\n","\n","![Lower Reception](resource/lower_6.png)"],"id":"4pEktKRDt6KV"},{"cell_type":"markdown","metadata":{"id":"c8NOyYuUt6KW"},"source":["## 2. Data Curation and Cleaning\n","\n","### Data Source and Format\n","\n","- The dataset is provided as a CSV file where each row is formatted as follows:\n","  ```\n","  kp1_x, kp1_y, kp2_x, kp2_y, ..., kpN_x, kpN_y, label\n","  ```\n","  where `label` is either \"upper\" or \"lower\".\n","\n","### Cleaning Process\n","\n","- Keypoint predictions generated by the pose estimation model were manually reviewed using overlay images.\n","- Samples with clearly incorrect skeletons or where keypoints were extracted from the wrong person were removed.\n","- Utility scripts were used to organize and curate the images and CSV files.\n","\n","**Sample of CSV Keypoint dataset:** ![Keypoints sample](resource/csvExample.png)", "\n", "**Wrong predictions of YOLO Keypoint Model:**", "\n", "![YOLO keypoint sample](resource/upper_25.png)"],"id":"c8NOyYuUt6KW"},{"cell_type":"markdown","metadata":{"id":"5Pne7wSat6KW"},"source":["## 3. Data Preprocessing\n","\n","The CSV file is loaded, and features (keypoints) and labels are separated. The labels are mapped to binary values (\"upper\" → 1, \"lower\" → 0), and the features are scaled using StandardScaler. This helps reduce the impact of absolute positions, allowing the model to focus on relative body posture.\n","\n","Below is the code used for data loading and preprocessing:"],"id":"5Pne7wSat6KW"},{"cell_type":"code","execution_count":null,"metadata":{"id":"IHmVabuXt6KW"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","def load_and_preprocess_data(csv_path):\n","    \"\"\"\n","    Load dataset from a CSV file and preprocess the data.\n","\n","    Expected CSV format per row:\n","        kp1_x, kp1_y, kp2_x, kp2_y, ..., kpN_x, kpN_y, label\n","    \"\"\"\n","    df = pd.read_csv(csv_path)\n","    X = df.iloc[:, :-1].values.astype(np.float32)\n","    y = df.iloc[:, -1].values\n","    label_map = {\"upper\": 1, \"lower\": 0}\n","    y = np.array([label_map[label.lower()] for label in y])\n","\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","\n","    return X_scaled, y, scaler\n","\n","# Example usage:\n","csv_path = \"data/original_dataset.csv\"  # Update this path as needed\n","X_scaled, y, scaler = load_and_preprocess_data(csv_path)\n","print(\"Data shape:\", X_scaled.shape)"],"id":"IHmVabuXt6KW"},{"cell_type":"markdown","metadata":{"id":"_e-iq2hYt6KX"},"source":["## 4. Model Building and Training\n","\n","We use a simple Multilayer Perceptron (MLP) with two hidden layers and dropout regularization. The decision to use a MLP was made as the input data (flattened keypoints) is low-dimensional and structured. If we were to use raw images (high-dimensional input) as input we would probably have decided on a CNN architecture. The network architecture is as follows (Dropout is added to reduce risk of overfitting):\n","\n","- **Dense(64, ReLU)** → **Dropout(0.3)**\n","- **Dense(32, ReLU)** → **Dropout(0.3)**\n","- **Dense(1, Sigmoid)**\n","\n","The dataset is split into training and test sets (80/20 split), with a validation split taken from the training set. EarlyStopping and ModelCheckpoint callbacks are used to prevent overfitting.\n","\n","Below is the code for model building and training:"],"id":"_e-iq2hYt6KX"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8U3h5yakt6KY"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.model_selection import train_test_split\n","\n","def build_model(input_dim):\n","    model = Sequential([\n","        Dense(64, activation='relu', input_shape=(input_dim,)),\n","        Dropout(0.3),\n","        Dense(32, activation='relu'),\n","        Dropout(0.3),\n","        Dense(1, activation='sigmoid')\n","    ])\n","    model.compile(optimizer=Adam(learning_rate=0.001),\n","                  loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, shuffle=True)\n","print(\"Training set shape:\", X_train.shape, \"Test set shape:\", X_test.shape)\n","\n","input_dim = X_train.shape[1]\n","model = build_model(input_dim)\n","model.summary()\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","checkpoint = ModelCheckpoint(\"models/volleyball_receive_classifier.h5\", monitor='val_loss', save_best_only=True)\n","\n","history = model.fit(X_train, y_train, epochs=20, batch_size=24,\n","                    validation_split=0.1, shuffle=True, callbacks=[early_stop, checkpoint])"],"id":"8U3h5yakt6KY"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7W_DHu9t6KY"},"outputs":[],"source":["# Plot training and validation curves\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training vs. Validation Loss\")\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['accuracy'], label='Train Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Training vs. Validation Accuracy\")\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"],"id":"b7W_DHu9t6KY"},{"cell_type":"markdown","metadata":{"id":"xPUoBtVVt6KY"},"source":["## 5. Model Evaluation\n","\n","I evaluate the model on the previously held-out test set. Below, we compute overall loss and accuracy, and also generate a detailed classification report and a confusion matrix."],"id":"xPUoBtVVt6KY"},{"cell_type":"code","execution_count":null,"metadata":{"id":"lkDOcIrSt6KY"},"outputs":[],"source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n","\n","# Detailed classification report and confusion matrix\n","from sklearn.metrics import classification_report, confusion_matrix\n","y_pred = (model.predict(X_test) > 0.5).astype(int)\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred, target_names=[\"lower\", \"upper\"]))\n","\n","import seaborn as sns\n","cm = confusion_matrix(y_test, y_pred)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"lower\", \"upper\"], yticklabels=[\"lower\", \"upper\"])\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()"],"id":"lkDOcIrSt6KY"},{"cell_type":"markdown","metadata":{"id":"w6mTJ7L-t6KZ"},"source":["## 6. Data Augmentation\n","\n","Due to the small size of our initial dataset, we apply data augmentation to quadruple its size. The following augmentations are used:\n","\n","- **Global Noise:** Adds small Gaussian noise to all keypoints.\n","- **Arm Shift:** Shifts keypoints corresponding to the arms horizontally.\n","- **Global Scaling:** Scales the entire skeleton about its centroid.\n","\n","Below is the code for the augmentation functions and an example of how to augment the dataset."],"id":"w6mTJ7L-t6KZ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bo6ez2jCt6KZ"},"outputs":[],"source":["def augment_global_noise(keypoints, noise_std=2.0):\n","    noise = np.random.normal(0, noise_std, keypoints.shape)\n","    return keypoints + noise\n","\n","def augment_arm_shift(keypoints, shift_range=5.0):\n","    kp_aug = keypoints.copy()\n","    left_arm_idx = [5, 7, 9]\n","    right_arm_idx = [6, 8, 10]\n","    left_shift = np.random.uniform(-shift_range, shift_range)\n","    right_shift = np.random.uniform(-shift_range, shift_range)\n","    for idx in left_arm_idx:\n","        if idx < kp_aug.shape[0]:\n","            kp_aug[idx, 0] += left_shift\n","    for idx in right_arm_idx:\n","        if idx < kp_aug.shape[0]:\n","            kp_aug[idx, 0] += right_shift\n","    return kp_aug\n","\n","def augment_global_scaling(keypoints, scale_range=(0.95, 1.05)):\n","    kp_aug = keypoints.copy()\n","    centroid = np.mean(kp_aug, axis=0)\n","    scale_factor = np.random.uniform(scale_range[0], scale_range[1])\n","    kp_aug = (kp_aug - centroid) * scale_factor + centroid\n","    return kp_aug\n","\n","def augment_sample(flat_sample):\n","    keypoints = flat_sample.reshape(-1, 2)\n","    augmented_samples = []\n","    augmented_samples.append(augment_global_noise(keypoints).flatten())\n","    augmented_samples.append(augment_arm_shift(keypoints).flatten())\n","    augmented_samples.append(augment_global_scaling(keypoints).flatten())\n","    return augmented_samples\n","\n","def augment_dataset(input_csv, output_csv):\n","    df = pd.read_csv(input_csv)\n","    feature_cols = df.columns[:-1]\n","    label_col = df.columns[-1]\n","    augmented_rows = []\n","\n","    for idx, row in df.iterrows():\n","        flat_sample = row[feature_cols].values.astype(np.float32)\n","        label = row[label_col]\n","        augmented_rows.append(np.concatenate([flat_sample, [label]]))\n","        for aug_sample in augment_sample(flat_sample):\n","            augmented_rows.append(np.concatenate([aug_sample, [label]]))\n","\n","    augmented_rows = np.array(augmented_rows)\n","    num_keypoints = augmented_rows.shape[1] - 1\n","    num_points = num_keypoints // 2\n","    columns = []\n","    for i in range(num_points):\n","        columns.append(f\"kp{i+1}_x\")\n","        columns.append(f\"kp{i+1}_y\")\n","    columns.append(\"label\")\n","\n","    df_aug = pd.DataFrame(augmented_rows, columns=columns)\n","    df_aug.to_csv(output_csv, index=False)\n","    print(f\"Augmented dataset saved to {output_csv}\")\n","\n","# Example usage:\n","# augment_dataset(\"data/original_dataset.csv\", \"data/augmented_dataset.csv\")"],"id":"bo6ez2jCt6KZ"},{"cell_type":"markdown","metadata":{"id":"WZalxG0bt6KZ"},"source":["## 7. Inference\n","\n","A separate inference pipeline (provided in `inference_receive_classifier.py`) is used to predict on new keypoint data. This notebook focuses on the training, evaluation, and augmentation process. Refer to the inference script for details on how new data is processed and classified."],"id":"WZalxG0bt6KZ"},{"cell_type":"markdown","metadata":{"id":"lJq1Gvaot6KZ"},"source":["## 8. Conclusions and Recommendations\n","\n","### Model Performance\n","\n","- The model achieved high overall accuracy with strong precision and recall on both classes.\n","- Training and validation curves indicate that overfitting was managed using early stopping and dropout.\n","\n","### Data Augmentation\n","\n","- Augmenting the data (via noise, arm shift, and scaling) effectively quadrupled the dataset, which helped improve model robustness.\n","\n","### Future Work\n","\n","- Consider further normalization (e.g., centering each sample by its centroid) to remove any bias from absolute positions.\n","- Validate the model on an external evaluation dataset to confirm generalization.\n","- Explore additional augmentation methods or more complex architectures if more data becomes available.\n","\n","Overall, this project demonstrates that a relatively simple MLP can effectively classify volleyball receptions using keypoint data."],"id":"lJq1Gvaot6KZ"},{"cell_type":"markdown","metadata":{"id":"8PhoHeRnt6KZ"},"source":["## 9. Appendix\n","\n","- **CSV Files:** Links or screenshots of the original and augmented datasets.\n","- **Sample Images:** Examples of correct and incorrect keypoint overlays.\n","- **Evaluation Reports:** Detailed classification reports and confusion matrices from test evaluations."],"id":"8PhoHeRnt6KZ"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.x"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}
